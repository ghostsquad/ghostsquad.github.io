<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on ghostsquad blog</title>
		<link>https://ghostsquad.me/posts/</link>
		<description>Recent content in Posts on ghostsquad blog</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>en-us</language>
		<copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
		<lastBuildDate>Sat, 16 Nov 2019 17:49:17 -0800</lastBuildDate>
		<atom:link href="https://ghostsquad.me/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Kubernetes on the Cheap - Part 1</title>
			<link>https://ghostsquad.me/posts/kubernetes-on-the-cheap-part-1/</link>
			<pubDate>Sat, 16 Nov 2019 17:49:17 -0800</pubDate>
			
			<guid>https://ghostsquad.me/posts/kubernetes-on-the-cheap-part-1/</guid>
			<description>How to run Kubernetes for less than $6 per month?
I wanted to play around with Kubernetes for personal learning, and even some personal projects. I wanted to deploy a website with a live backend, but I didn&amp;rsquo;t really want to be bound to cPanel, or terrible performance issues on shared hosting providers. This was also an opportunity for me to learn more about deploying an application end2end and managing it myself.</description>
			<content type="html"><![CDATA[

<p>How to run Kubernetes for less than $6 per month?</p>

<p>I wanted to play around with Kubernetes for personal learning, and even some personal projects. I wanted to deploy a website with a live backend, but I didn&rsquo;t really want to be bound to cPanel, or terrible performance issues on shared hosting providers. This was also an opportunity for me to learn more about deploying an application end2end and managing it myself. This post details the exact steps to deploy a Kubernetes cluster to Google Cloud Platform, and run a single, low-utilization application for about $5/mo. It includes all the pitfalls, gotchas, shortcuts, workarounds, optimizations, etc in order to make it work, step by step.</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
<li><a href="#table-of-contents">Table of Contents</a></li>
<li><a href="#create-a-gcp-account--project">Create a GCP Account &amp; Project</a></li>
<li><a href="#create-a-gke-cluster">Create a GKE Cluster</a>

<ul>
<li><a href="#pre-emptible-instances">Pre-emptible Instances</a></li>
</ul></li>
<li><a href="#optimizations">Optimizations</a>

<ul>
<li><a href="#fluentd-gcp-scaler">fluentd-gcp-scaler</a></li>
<li><a href="#kube-dns-autoscaler">kube-dns-autoscaler</a></li>
</ul></li>
<li><a href="#resource-utilization-overview">Resource Utilization Overview</a></li>
<li><a href="#deploy-nginx-ingress">Deploy Nginx Ingress</a></li>
<li><a href="#create-a-firewall-rule-to-allow-traffic-to-the-nodes">Create a firewall rule to allow traffic to the nodes</a></li>
<li><a href="#deploy-a-simple-app">Deploy a simple app</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>

<h2 id="create-a-gcp-account-project">Create a GCP Account &amp; Project</h2>

<ol>
<li>You can create or select a GCP Project from the <a href="https://console.cloud.google.com/projectselector2/home/dashboard">Project Selector Page</a>.</li>
<li>Make sure that billing is enabled for your Google Cloud Platform project. <a href="https://cloud.google.com/billing/docs/how-to/modify-project">Learn how to confirm billing is enabled for your project</a>.</li>
</ol>

<p>For this article, I&rsquo;ve created a new project called <code>kubernetes-on-the-cheap</code>. For the remainder of the article, I&rsquo;ll be showing you <code>gcloud</code> or <code>kubectl</code> commands to run instead of walking through how to do this from the UI, though it&rsquo;s also pretty simple from the UI, it just requires a few more steps and screenshots.</p>

<p>Unless otherwise noted, all commands listed will be run from the GCP Cloud Shell.</p>

<p>To reduce repetition, I&rsquo;ve aliased <code>kubectl</code> to <code>k</code></p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">alias</span> <span class="nv">k</span><span class="o">=</span>kubectl</code></pre></div>
<p>or</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">echo</span> <span class="s2">&#34;alias k=kubectl&#34;</span> &gt;&gt; <span class="nv">$HOME</span>/.bashrc</code></pre></div>
<h2 id="create-a-gke-cluster">Create a GKE Cluster</h2>

<p>GKE (Google Kubernetes Engine) is actually FREE on GCP&hellip; well the master nodes are. You can create a cluster without any worker nodes at no cost. That&rsquo;s the next step. First, navigate to <a href="https://console.cloud.google.com/kubernetes/list?project=kubernetes-on-the-cheap">https://console.cloud.google.com/kubernetes/list?project=kubernetes-on-the-cheap</a> but replacing the <code>project</code> with your own project name. Google has to enable the <code>Kubernetes Engine API</code>, and it takes a few minutes.</p>

<p>Here&rsquo;s the command to run, but you&rsquo;ll have to fill in a few things yourself. The important part to note here is that this creates a single-zone GKE cluster (for the master nodes). If you don&rsquo;t do this, when you create node groups, you&rsquo;ll be forced to have a minimum of 3 nodes (1 per zone). I couldn&rsquo;t find a way around there. You can read more about this in <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/regional-clusters">the docs</a>. The main downside is that when the cluster upgrades, you won&rsquo;t be able to access the control plane. The data plane (where your apps run) is unaffected.</p>

<p>Most of the next commands can be run from the google cloud console via their website.</p>

<p>Run this locally, and copy the output (or visit the website below to get your home IP address)</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nv">MY_HOME_IP</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span>curl https://ifconfig.co/ip<span class="k">)</span><span class="s2">&#34;</span>
<span class="nb">echo</span> <span class="s2">&#34;MY_HOME_IP=</span><span class="si">${</span><span class="nv">MY_HOME_IP</span><span class="si">}</span><span class="s2">&#34;</span></code></pre></div>
<p>Run this from the Cloud Shell console</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nv">PROJECT_NAME</span><span class="o">=</span><span class="s2">&#34;kubernetes-on-the-cheap&#34;</span>
<span class="nv">REGION</span><span class="o">=</span><span class="s2">&#34;us-west1&#34;</span>
<span class="nv">ZONE_ID</span><span class="o">=</span><span class="s2">&#34;a&#34;</span>
<span class="nv">ZONE</span><span class="o">=</span><span class="s2">&#34;</span><span class="si">${</span><span class="nv">REGION</span><span class="si">}</span><span class="s2">-</span><span class="si">${</span><span class="nv">ZONE_ID</span><span class="si">}</span><span class="s2">&#34;</span>

gcloud beta container <span class="se">\
</span><span class="se"></span>  --project <span class="s2">&#34;</span><span class="si">${</span><span class="nv">PROJECT_NAME</span><span class="si">}</span><span class="s2">&#34;</span> <span class="se">\
</span><span class="se"></span>  clusters create <span class="s2">&#34;hobby-1&#34;</span> <span class="se">\
</span><span class="se"></span>  --zone <span class="s2">&#34;</span><span class="si">${</span><span class="nv">ZONE</span><span class="si">}</span><span class="s2">&#34;</span> <span class="se">\
</span><span class="se"></span>  --no-enable-basic-auth <span class="se">\
</span><span class="se"></span>  --release-channel <span class="s2">&#34;regular&#34;</span> <span class="se">\
</span><span class="se"></span>  --machine-type <span class="s2">&#34;g1-small&#34;</span> <span class="se">\
</span><span class="se"></span>  --image-type <span class="s2">&#34;COS&#34;</span> <span class="se">\
</span><span class="se"></span>  --disk-type <span class="s2">&#34;pd-standard&#34;</span> <span class="se">\
</span><span class="se"></span>  --disk-size <span class="s2">&#34;30&#34;</span> <span class="se">\
</span><span class="se"></span>  --metadata disable-legacy-endpoints<span class="o">=</span><span class="nb">true</span> <span class="se">\
</span><span class="se"></span>  --scopes <span class="s2">&#34;https://www.googleapis.com/auth/devstorage.read_only&#34;</span>,<span class="s2">&#34;https://www.googleapis.com/auth/logging.write&#34;</span>,<span class="s2">&#34;https://www.googleapis.com/auth/monitoring&#34;</span>,<span class="s2">&#34;https://www.googleapis.com/auth/servicecontrol&#34;</span>,<span class="s2">&#34;https://www.googleapis.com/auth/service.management.readonly&#34;</span>,<span class="s2">&#34;https://www.googleapis.com/auth/trace.append&#34;</span> <span class="se">\
</span><span class="se"></span>  --preemptible <span class="se">\
</span><span class="se"></span>  --num-nodes <span class="s2">&#34;1&#34;</span> <span class="se">\
</span><span class="se"></span>  --enable-stackdriver-kubernetes <span class="se">\
</span><span class="se"></span>  --enable-ip-alias <span class="se">\
</span><span class="se"></span>  --network <span class="s2">&#34;projects/</span><span class="si">${</span><span class="nv">PROJECT_NAME</span><span class="si">}</span><span class="s2">/global/networks/default&#34;</span> <span class="se">\
</span><span class="se"></span>  --subnetwork <span class="s2">&#34;projects/</span><span class="si">${</span><span class="nv">PROJECT_NAME</span><span class="si">}</span><span class="s2">/regions/</span><span class="si">${</span><span class="nv">REGION</span><span class="si">}</span><span class="s2">/subnetworks/default&#34;</span> <span class="se">\
</span><span class="se"></span>  --default-max-pods-per-node <span class="s2">&#34;110&#34;</span> <span class="se">\
</span><span class="se"></span>  --enable-master-authorized-networks <span class="se">\
</span><span class="se"></span>  --master-authorized-networks <span class="s2">&#34;</span><span class="si">${</span><span class="nv">MY_HOME_IP</span><span class="si">}</span><span class="s2">/32&#34;</span> <span class="se">\
</span><span class="se"></span>  --addons HorizontalPodAutoscaling <span class="se">\
</span><span class="se"></span>  --enable-autoupgrade <span class="se">\
</span><span class="se"></span>  --enable-autorepair <span class="se">\
</span><span class="se"></span>  --maintenance-window-start <span class="s2">&#34;2019-11-15T10:00:00Z&#34;</span> <span class="se">\
</span><span class="se"></span>  --maintenance-window-end <span class="s2">&#34;2019-11-15T14:00:00Z&#34;</span> <span class="se">\
</span><span class="se"></span>  --maintenance-window-recurrence <span class="s2">&#34;FREQ=WEEKLY;BYDAY=MO,TU,WE,TH&#34;</span></code></pre></div>
<ul>
<li><code>--project</code> - change this to your project name</li>
<li><code>hobby-1</code> - change this to a cluster name of your choosing</li>
<li><code>--zone &quot;us-west1-a&quot;</code> - I chose <code>us-west1-a</code> because it&rsquo;s the cheapest region in the US (<code>us-central1</code> is the same low price), and that&rsquo;s also where I live. I don&rsquo;t plan on running anything that would have any significant performance impact for users from say the east coast, so this is not much of concern. I&rsquo;ll talk more about this in the next section, <a href="#zones-regions-and-other-network-to-consider">Zones, Regions, and other networking to consider</a>.</li>
<li><code>--no-enable-basic-auth</code> - <em>REASONABLE DEFAULT</em></li>
<li><code>--release-chanel &quot;regular&quot;</code> -  I chose to keep my cluster regularly upgraded, since this was a hobby cluster, I don&rsquo;t really mind, and it&rsquo;s may also later become a good exercise in managing availability.</li>
<li><code>--machine-type &quot;g1-small&quot;</code> - <a href="https://cloud.google.com/compute/vm-instance-pricing#sharedcore">a <code>g1-small</code> is $5.11 per month when pre-emptible</a>. More on <a href="#pre-emptible-instances">pre-emptible instances below</a>. As of this post, the <code>f1-micro</code> is too small to run while also enabling the stackdriver addon.</li>
<li><code>--image-type &quot;COS&quot;</code> - <em>REASONABLE DEFAULT</em></li>
<li><code>--disk-type &quot;pd-standard&quot;</code> - <em>REASONABLE DEFAULT</em></li>
<li><code>--disk-size 30</code> - <em>REASONABLE DEFAULT</em></li>
<li><code>--metadata disable-legacy-endpoints=true</code> - this was a default setting for clusters &gt; <code>1.12</code></li>
<li><code>--scopes ...</code> - <em>REASONABLE DEFAULT</em></li>
<li><code>--preemptible</code> - This is important, as stated above, the cost is significantly less. More on <a href="#pre-emptible-instances">pre-emptible instances below</a></li>
<li><code>--no-nodes &quot;1&quot;</code> - This will create 3 nodes (1 per zone) in the default node pool. We&rsquo;ll delete that node pool as soon as the cluster comes up, so don&rsquo;t worry about this much.</li>
<li><code>--enable-stackdriver-kubernetes</code> - Stackdriver is <a href="https://cloud.google.com/stackdriver/">mostly free</a>, if you use it sparingly, so let&rsquo;s enable this so we can monitor our cluster.</li>
<li><code>--enable-ip-alias</code> - <em>REASONABLE DEFAULT</em></li>
<li><code>--network ...</code> - <em>REQUIRED</em></li>
<li><code>--subnetwork ...</code> - <em>REQUIRED</em></li>
<li><code>--default-max-pods-per-node &quot;110&quot;</code> - <em>REASONABLE DEFAULT</em></li>
<li><code>--enable-master-authorized-networks</code> - This is to restrict who can access the master nodes (K8s API). The next setting will use your home IP address.</li>
<li><code>--master-authorized-networks &quot;${MY_HOME_IP}/32&quot;</code> - Restrict access to the K8s API to your home IP address. This can be updated on demand, and <a href="#updating-cluster-authorized-networks">I&rsquo;ll show you how to do that later</a>.</li>
<li><code>--addons HorizontalPodAutoscaling</code> - This is not needed, since you probably won&rsquo;t use it, but doesn&rsquo;t hurt.</li>
<li><code>--enable-autoupgrade</code> - I checked this cause with a regional cluster, I don&rsquo;t really want to upgrade manually.</li>
<li><code>--enable-autorepair</code> - Seems like a good idea.</li>
<li><code>--maintennce-window-*</code> - Choose what&rsquo;s right for you. For my purposes, I expect more traffic during the weekend, so I&rsquo;m restricting maintence to 2AM on the weekdays.</li>
</ul>

<p>This command will immediately create a cluster and a node pool with 3 nodes in it. That&rsquo;s a bit too much for my liking, so let&rsquo;s delete the default node pool, and recreate it so that there&rsquo;s only 1 node in it.</p>

<h3 id="pre-emptible-instances">Pre-emptible Instances</h3>

<p>You can read more about preemptible instances from the offical docs:</p>

<p><a href="https://cloud.google.com/compute/docs/instances/preemptible">https://cloud.google.com/compute/docs/instances/preemptible</a></p>

<h2 id="optimizations">Optimizations</h2>

<p>When the cluster comes up, you&rsquo;ll already have quite a few deployed pods on the cluster. If this was a large cluster, the defaults would probably be fine. But we are on a budget! So we need to modify some of these.</p>

<p>Some of this can be found in google&rsquo;s docs <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/small-cluster-tuning">small-cluster-tuning</a>.</p>

<p>First, you&rsquo;ll need to authenticate to the cluster to run kubectl commands.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">gcloud container clusters get-credentials hobby-1 --zone us-west1-a --project kubernetes-on-the-cheap</code></pre></div>
<p>Here we can get a quick glance at what&rsquo;s running, and it&rsquo;s actual usage. Note that cpu/mem requests can and usually are greater than idle usage. The kubernetes schedule will refuse to deploy pods if the sum of requested resources is greater than the allocatable amount for that resource.</p>
<div class="highlight"><pre class="chroma"><code class="language-txt" data-lang="txt">k -n kube-system top pods
NAME                                                        CPU(cores)   MEMORY(bytes)
event-exporter-v0.2.5-7df89f4b8f-bh7gj                      1m           16Mi
fluentd-gcp-scaler-54ccb89d5-x9w4n                          0m           32Mi
fluentd-gcp-v3.1.1-tmzdc                                    11m          134Mi
heapster-dbf95c595-5zg5m                                    1m           34Mi
kube-dns-5877696fb4-hwwtt                                   2m           27Mi
kube-dns-autoscaler-85f8bdb54-jhvsj                         1m           3Mi
kube-proxy-gke-hobby-1-default-pool-d97956f1-dzjm           1m           11Mi
metrics-server-v0.3.1-8d4c5db46-np6pl                       1m           16Mi
prometheus-to-sd-z2kw7                                      1m           11Mi
stackdriver-metadata-agent-cluster-level-684c9bb574-vkjhw   4m           17Mi</code></pre></div>
<p>We&rsquo;ll be able to recover some of this (detailed below). But the rest is outside of our control, since these are GKE addons. Any modification to them simply gets reverted.</p>

<h3 id="fluentd-gcp-scaler">fluentd-gcp-scaler</h3>

<p>This is part of the StackDriver addon.</p>

<p>I believe this is similar to a <code>VerticalPodAutoscaler</code>, which I don&rsquo;t need, so here&rsquo;s how to disable it. Thankfully this is one of the deployments that doesn&rsquo;t mind being scaled to 0.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">k -n kube-system scale deployment fluentd-gcp-scaler --replicas<span class="o">=</span><span class="m">0</span></code></pre></div>
<h3 id="kube-dns-autoscaler">kube-dns-autoscaler</h3>

<p>I don&rsquo;t need kube-dns to scale, so here&rsquo;s how to disable this.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">k -n kube-system scale deployment kube-dns-autoscaler --replicas<span class="o">=</span><span class="m">0</span></code></pre></div>
<h2 id="resource-utilization-overview">Resource Utilization Overview</h2>

<table>
<thead>
<tr>
<th>Resource</th>
<th align="right">Real</th>
<th align="right">Requested</th>
<th align="right">Allocatable</th>
<th align="right">Remaining (Req-Alloc)</th>
</tr>
</thead>

<tbody>
<tr>
<td>CPU</td>
<td align="right">20m</td>
<td align="right">339m</td>
<td align="right">940m</td>
<td align="right">601m</td>
</tr>

<tr>
<td>Mem</td>
<td align="right">269Mi</td>
<td align="right">488Mi</td>
<td align="right">1220Mi</td>
<td align="right">732Mi</td>
</tr>
</tbody>
</table>

<p>Much of this is coming from StackDriver addon pods. Maybe in another post, I&rsquo;ll look into an alternative solution, but for now, the remainder is more than enough for a small backend webserver.</p>

<h2 id="deploy-nginx-ingress">Deploy Nginx Ingress</h2>

<p>Loadbalancers in GCP have a minimum of $0.60/day or $18/mo charge, so to avoid creating one, we need to setup nginx ingress in a special way.</p>

<p>If nginx ingress controller is set to use the host network, it can bind on port 80 and 443. This means that if we can create a route to any given node on the cluster, 80 and 443 will route to nginx.</p>

<p>The following manifests are derived from the <a href="https://kubernetes.github.io/ingress-nginx/deploy/">manifests online</a>, but differ in the following ways:</p>

<ul>
<li>No <code>service</code> resource is necessary (or desired)</li>
<li>Remove the reference in the controller args to the <code>service</code> resource (that we aren&rsquo;t deploying)</li>
<li>Set CPU/Mem resource requests</li>
<li>Changing from <code>deployment</code> to <code>daemonset</code></li>
<li>Set <code>hostNetwork: true</code> and <code>dnsPolicy: ClusterFirstWithHostNet</code></li>
</ul>

<p>Run this to deploy the nginx ingress controller:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">cat &gt; nginx.yaml <span class="s">&lt;&lt; EOF
</span><span class="s">apiVersion: v1
</span><span class="s">kind: Namespace
</span><span class="s">metadata:
</span><span class="s">  name: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">
</span><span class="s">---
</span><span class="s">
</span><span class="s">kind: ConfigMap
</span><span class="s">apiVersion: v1
</span><span class="s">metadata:
</span><span class="s">  name: nginx-configuration
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">
</span><span class="s">---
</span><span class="s">kind: ConfigMap
</span><span class="s">apiVersion: v1
</span><span class="s">metadata:
</span><span class="s">  name: tcp-services
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">
</span><span class="s">---
</span><span class="s">kind: ConfigMap
</span><span class="s">apiVersion: v1
</span><span class="s">metadata:
</span><span class="s">  name: udp-services
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">
</span><span class="s">---
</span><span class="s">apiVersion: v1
</span><span class="s">kind: ServiceAccount
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-serviceaccount
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">
</span><span class="s">---
</span><span class="s">apiVersion: rbac.authorization.k8s.io/v1beta1
</span><span class="s">kind: ClusterRole
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-clusterrole
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">rules:
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - configmaps
</span><span class="s">      - endpoints
</span><span class="s">      - nodes
</span><span class="s">      - pods
</span><span class="s">      - secrets
</span><span class="s">    verbs:
</span><span class="s">      - list
</span><span class="s">      - watch
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - nodes
</span><span class="s">    verbs:
</span><span class="s">      - get
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - services
</span><span class="s">    verbs:
</span><span class="s">      - get
</span><span class="s">      - list
</span><span class="s">      - watch
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - events
</span><span class="s">    verbs:
</span><span class="s">      - create
</span><span class="s">      - patch
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;extensions&#34;
</span><span class="s">      - &#34;networking.k8s.io&#34;
</span><span class="s">    resources:
</span><span class="s">      - ingresses
</span><span class="s">    verbs:
</span><span class="s">      - get
</span><span class="s">      - list
</span><span class="s">      - watch
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;extensions&#34;
</span><span class="s">      - &#34;networking.k8s.io&#34;
</span><span class="s">    resources:
</span><span class="s">      - ingresses/status
</span><span class="s">    verbs:
</span><span class="s">      - update
</span><span class="s">
</span><span class="s">---
</span><span class="s">apiVersion: rbac.authorization.k8s.io/v1beta1
</span><span class="s">kind: Role
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-role
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">rules:
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - configmaps
</span><span class="s">      - pods
</span><span class="s">      - secrets
</span><span class="s">      - namespaces
</span><span class="s">    verbs:
</span><span class="s">      - get
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - configmaps
</span><span class="s">    resourceNames:
</span><span class="s">      # Defaults to &#34;&lt;election-id&gt;-&lt;ingress-class&gt;&#34;
</span><span class="s">      # Here: &#34;&lt;ingress-controller-leader&gt;-&lt;nginx&gt;&#34;
</span><span class="s">      # This has to be adapted if you change either parameter
</span><span class="s">      # when launching the nginx-ingress-controller.
</span><span class="s">      - &#34;ingress-controller-leader-nginx&#34;
</span><span class="s">    verbs:
</span><span class="s">      - get
</span><span class="s">      - update
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - configmaps
</span><span class="s">    verbs:
</span><span class="s">      - create
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - endpoints
</span><span class="s">    verbs:
</span><span class="s">      - get
</span><span class="s">
</span><span class="s">---
</span><span class="s">apiVersion: rbac.authorization.k8s.io/v1beta1
</span><span class="s">kind: RoleBinding
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-role-nisa-binding
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">roleRef:
</span><span class="s">  apiGroup: rbac.authorization.k8s.io
</span><span class="s">  kind: Role
</span><span class="s">  name: nginx-ingress-role
</span><span class="s">subjects:
</span><span class="s">  - kind: ServiceAccount
</span><span class="s">    name: nginx-ingress-serviceaccount
</span><span class="s">    namespace: ingress-nginx
</span><span class="s">
</span><span class="s">---
</span><span class="s">apiVersion: rbac.authorization.k8s.io/v1beta1
</span><span class="s">kind: ClusterRoleBinding
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-clusterrole-nisa-binding
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">roleRef:
</span><span class="s">  apiGroup: rbac.authorization.k8s.io
</span><span class="s">  kind: ClusterRole
</span><span class="s">  name: nginx-ingress-clusterrole
</span><span class="s">subjects:
</span><span class="s">  - kind: ServiceAccount
</span><span class="s">    name: nginx-ingress-serviceaccount
</span><span class="s">    namespace: ingress-nginx
</span><span class="s">
</span><span class="s">---
</span><span class="s">
</span><span class="s">apiVersion: apps/v1
</span><span class="s">kind: Daemonset
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-controller
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">spec:
</span><span class="s">  selector:
</span><span class="s">    matchLabels:
</span><span class="s">      app.kubernetes.io/name: ingress-nginx
</span><span class="s">      app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">  template:
</span><span class="s">    metadata:
</span><span class="s">      labels:
</span><span class="s">        app.kubernetes.io/name: ingress-nginx
</span><span class="s">        app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">      annotations:
</span><span class="s">        prometheus.io/port: &#34;10254&#34;
</span><span class="s">        prometheus.io/scrape: &#34;true&#34;
</span><span class="s">    spec:
</span><span class="s">      hostNetwork: true
</span><span class="s">      dnsPolicy: ClusterFirstWithHostNet
</span><span class="s">      terminationGracePeriodSeconds: 300
</span><span class="s">      serviceAccountName: nginx-ingress-serviceaccount
</span><span class="s">      nodeSelector:
</span><span class="s">        kubernetes.io/os: linux
</span><span class="s">      containers:
</span><span class="s">        - name: nginx-ingress-controller
</span><span class="s">          image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.26.1
</span><span class="s">          args:
</span><span class="s">            - /nginx-ingress-controller
</span><span class="s">            - --configmap=$(POD_NAMESPACE)/nginx-configuration
</span><span class="s">            - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services
</span><span class="s">            - --udp-services-configmap=$(POD_NAMESPACE)/udp-services
</span><span class="s">            - --annotations-prefix=nginx.ingress.kubernetes.io
</span><span class="s">          securityContext:
</span><span class="s">            allowPrivilegeEscalation: true
</span><span class="s">            capabilities:
</span><span class="s">              drop:
</span><span class="s">                - ALL
</span><span class="s">              add:
</span><span class="s">                - NET_BIND_SERVICE
</span><span class="s">            # www-data -&gt; 33
</span><span class="s">            runAsUser: 33
</span><span class="s">          env:
</span><span class="s">            - name: POD_NAME
</span><span class="s">              valueFrom:
</span><span class="s">                fieldRef:
</span><span class="s">                  fieldPath: metadata.name
</span><span class="s">            - name: POD_NAMESPACE
</span><span class="s">              valueFrom:
</span><span class="s">                fieldRef:
</span><span class="s">                  fieldPath: metadata.namespace
</span><span class="s">          ports:
</span><span class="s">            - name: http
</span><span class="s">              containerPort: 80
</span><span class="s">            - name: https
</span><span class="s">              containerPort: 443
</span><span class="s">          livenessProbe:
</span><span class="s">            failureThreshold: 3
</span><span class="s">            httpGet:
</span><span class="s">              path: /healthz
</span><span class="s">              port: 10254
</span><span class="s">              scheme: HTTP
</span><span class="s">            initialDelaySeconds: 10
</span><span class="s">            periodSeconds: 10
</span><span class="s">            successThreshold: 1
</span><span class="s">            timeoutSeconds: 10
</span><span class="s">          readinessProbe:
</span><span class="s">            failureThreshold: 3
</span><span class="s">            httpGet:
</span><span class="s">              path: /healthz
</span><span class="s">              port: 10254
</span><span class="s">              scheme: HTTP
</span><span class="s">            periodSeconds: 10
</span><span class="s">            successThreshold: 1
</span><span class="s">            timeoutSeconds: 10
</span><span class="s">          resources:
</span><span class="s">            requests:
</span><span class="s">              cpu: 2m
</span><span class="s">              memory: 60Mi
</span><span class="s">          lifecycle:
</span><span class="s">            preStop:
</span><span class="s">              exec:
</span><span class="s">                command:
</span><span class="s">                  - /wait-shutdown
</span><span class="s">
</span><span class="s">---
</span><span class="s">EOF</span>

kubectl apply -f nginx.yaml</code></pre></div>
<h2 id="create-a-firewall-rule-to-allow-traffic-to-the-nodes">Create a firewall rule to allow traffic to the nodes</h2>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nv">TARGET_TAG</span><span class="o">=</span><span class="k">$(</span>gcloud compute instances list --format<span class="o">=</span>json <span class="p">|</span> jq -r <span class="s1">&#39;.[0].tags.items[0]&#39;</span><span class="k">)</span>

gcloud compute <span class="se">\
</span><span class="se"></span>  --project<span class="o">=</span>kubernetes-on-the-cheap <span class="se">\
</span><span class="se"></span>  firewall-rules create http-ingress <span class="se">\
</span><span class="se"></span>  --direction<span class="o">=</span>INGRESS <span class="se">\
</span><span class="se"></span>  --priority<span class="o">=</span><span class="m">1000</span> <span class="se">\
</span><span class="se"></span>  --network<span class="o">=</span>default <span class="se">\
</span><span class="se"></span>  --action<span class="o">=</span>ALLOW <span class="se">\
</span><span class="se"></span>  --rules<span class="o">=</span>tcp:80,tcp:443 <span class="se">\
</span><span class="se"></span>  --source-ranges<span class="o">=</span><span class="m">0</span>.0.0.0/0 <span class="se">\
</span><span class="se"></span>  --target-tags<span class="o">=</span><span class="nv">$TARGET_TAG</span></code></pre></div>
<h2 id="deploy-a-simple-app">Deploy a simple app</h2>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nv">EXT_IP</span><span class="o">=</span><span class="k">$(</span>gcloud compute instances list --format<span class="o">=</span>json <span class="p">|</span> jq -r <span class="s1">&#39;.[0].networkInterfaces[0].accessConfigs[0].natIP&#39;</span><span class="k">)</span>
<span class="nb">echo</span> <span class="nv">$EXT_IP</span>
<span class="nv">HOST</span><span class="o">=</span><span class="s2">&#34;test.</span><span class="si">${</span><span class="nv">EXT_IP</span><span class="si">}</span><span class="s2">.xip.io&#34;</span>

cat &gt; hello.yaml <span class="s">&lt;&lt;EOF
</span><span class="s">apiVersion: apps/v1
</span><span class="s">kind: Deployment
</span><span class="s">metadata:
</span><span class="s">  name: hello
</span><span class="s">  labels:
</span><span class="s">    app: hello
</span><span class="s">spec:
</span><span class="s">  selector:
</span><span class="s">    matchLabels:
</span><span class="s">      app: hello
</span><span class="s">      tier: web
</span><span class="s">  template:
</span><span class="s">    metadata:
</span><span class="s">      labels:
</span><span class="s">        app: hello
</span><span class="s">        tier: web
</span><span class="s">    spec:
</span><span class="s">      containers:
</span><span class="s">      - name: hello
</span><span class="s">        image: gcr.io/google-samples/hello-app:1.0
</span><span class="s">        ports:
</span><span class="s">        - containerPort: 8080
</span><span class="s">---
</span><span class="s">apiVersion: v1
</span><span class="s">kind: Service
</span><span class="s">metadata:
</span><span class="s">  name: hello
</span><span class="s">spec:
</span><span class="s">  selector:
</span><span class="s">    app: hello
</span><span class="s">  ports:
</span><span class="s">    - protocol: TCP
</span><span class="s">      port: 80
</span><span class="s">      targetPort: 8080
</span><span class="s">---
</span><span class="s">apiVersion: extensions/v1beta1
</span><span class="s">kind: Ingress
</span><span class="s">metadata:
</span><span class="s">  name: hello
</span><span class="s">  annotations:
</span><span class="s">    kubernetes.io/ingress.class: &#34;nginx&#34;
</span><span class="s">spec:
</span><span class="s">  rules:
</span><span class="s">  - host: test.${EXT_IP}.xip.io
</span><span class="s">    http:
</span><span class="s">      paths:
</span><span class="s">      - path: /
</span><span class="s">        backend:
</span><span class="s">          serviceName: hello
</span><span class="s">          servicePort: 80
</span><span class="s">---
</span><span class="s">EOF</span>

kubectl create -f hello.yaml

<span class="nb">echo</span> <span class="s2">&#34;go</span></code></pre></div>
<p>This works, but we have one major issue, and that&rsquo;s the node IP address will change every 24 hours because the instance is pre-emptible. (and also this means the <code>host</code> in the ingress will need to be updated every 24 hours)</p>

<p>We&rsquo;ll address this in the next part of this series!</p>

<h2 id="conclusion">Conclusion</h2>

<p>We&rsquo;ve deployed a cluster to GKE running a single node. We deployed nginx ingress to run on the host network to avoid creating a load balancer, and we deployed a simple test application.</p>

<p>The problems which we need to address in the next part are:</p>

<ul>
<li>Setting up domain that points to the cluster, so that we don&rsquo;t have to update the ingress</li>
<li>Setting up <a href="https://github.com/kubernetes-sigs/external-dns">external-dns</a> to automatically update our domain with the list of IPs of hosts (when the get pre-empted)</li>
<li>Setup <a href="k8s-node-termination-handler">node-termination-handler</a> to further improve shutdowns</li>
<li>Setup <a href="https://spotinst.com/pricing/">SpotInst</a> in order to handle rolling instances on a regular basis in a controlled way, and scaling the cluster temporarily while doing so.</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>The Little Things</title>
			<link>https://ghostsquad.me/posts/the-little-things/</link>
			<pubDate>Fri, 23 Aug 2019 18:44:31 -0700</pubDate>
			
			<guid>https://ghostsquad.me/posts/the-little-things/</guid>
			<description>One thing I&amp;rsquo;ve noticed over the years is that the little things in software development often get overlooked as &amp;ldquo;bike shedding&amp;rdquo; moments, and yet there&amp;rsquo;s significant value in establishing a standard, convention, and even automation around these overlooked things. Let&amp;rsquo;s dive right in:
Git Commits Following conventional commits standards can allow you to do things like:
 Automatically generate CHANGELOGs Automatically determine semantic version bump Communicate nature of changes to teammates, public, stakeholders Used to change build pipeline behavior at runtime to publish code automatically Enhance readability of git commit history  I&amp;rsquo;m in the SRE/DevOps/PaaS space, and I often find myself wishing I had more time to write weekly newsletters or similar communications to internal teams to increase the visibility of the new features, bugfixes, and other changes that are being delivered.</description>
			<content type="html"><![CDATA[

<p>One thing I&rsquo;ve noticed over the years is that the little things in software development often get overlooked as &ldquo;bike shedding&rdquo; moments, and yet there&rsquo;s significant value in establishing a standard, convention, and even automation around these overlooked things. Let&rsquo;s dive right in:</p>

<h3 id="git-commits">Git Commits</h3>

<p>Following <a href="https://www.conventionalcommits.org/en/v1.0.0-beta.4/">conventional commits</a> standards can allow you to do things like:</p>

<ol>
<li>Automatically generate CHANGELOGs</li>
<li>Automatically determine semantic version bump</li>
<li>Communicate nature of changes to teammates, public, stakeholders</li>
<li>Used to change build pipeline behavior at runtime to publish code automatically</li>
<li>Enhance readability of git commit history</li>
</ol>

<p>I&rsquo;m in the SRE/DevOps/PaaS space, and I often find myself wishing I had more time to write weekly newsletters  or similar communications to internal teams to increase the visibility of the new features, bugfixes, and other changes that are being delivered. This includes beta releases, and getting volunteers to provide feedback on tools/services before distributing them to the wider engineering organization. With this said, I cannot overstate the value of #1 and #3 in the above list. I don&rsquo;t mean a <a href="https://about.gitlab.com/releases/">hard-to-read, never-ending list</a> either. Imagine being able to <em>generate</em> a releases page like <a href="https://about.gitlab.com/2019/08/22/gitlab-12-2-released/index.html">Gitlab&rsquo;s 12.2 release</a>. This is theoretically possible through a combination of well-written commits (that are machine parseable) and well-written epics, that can be queried.</p>

<p>Combine this with <a href="https://chris.beams.io/posts/git-commit/#seven-rules">Chris Beams&rsquo;: How to Write a Git Commit Message</a> and it makes it trivial to go back in time an figure out why something was done.</p>

<h3 id="project-structure-naming">Project Structure &amp; Naming</h3>

<p>Conventions over Configuration. This applies to a project directory structure &amp; naming too. Here&rsquo;s some benefits of coming up with and sticking to a polyglot convention, similar to <a href="https://github.com/golang-standards/project-layout">Go project structure recommendations</a>.</p>

<ol>
<li>CI/CD templated/generated pipelines

<ul>
<li>If your project name is valid DNS (and all lowercase), it makes it easy to use (without modification) as your kubernetes namespace (or namespace prefix).</li>
<li><code>Dockerfile</code> in the root of your repo? We have a pre-baked step to build/publish without any additional configuration.</li>
<li>Using <code>make</code>? A standard pipeline can make some assumptions for you about commands to run without requiring explicit configuration.</li>
</ul></li>
<li>Enhance readability &amp; maintenance by teammates and external teams. Sticking to a convention means that someone doesn&rsquo;t need to learn &ldquo;how <em>your</em> repo does it&rdquo;.</li>
<li>New projects can be <a href="https://github.com/facebook/create-react-app">templatized/generated</a>. If you have the pleasure of being able to spinup &amp; deploy greenfield applications on a regular basis, this becomes an automatable step.</li>
</ol>

<h3 id="tags-labels-annotations">Tags, Labels, Annotations</h3>

<p>Again, this is all about automation. It makes sense to have a standard set of keys and a convention for custom keys that are forward compatible with changes to the standard. Use this same standard for your cloud provider, like AWS, as well as Kubernetes resources.</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml">company.io/environment<span class="p">:</span><span class="w"> </span>prd<span class="w">
</span><span class="w"></span>company.io/team<span class="p">:</span><span class="w"> </span>sig-api<span class="w">
</span><span class="w"></span>company.io/contact<span class="p">:</span><span class="w"> </span>sig-api@company.io<span class="w">
</span><span class="w"></span>company.io/managed-by<span class="p">:</span><span class="w"> </span>terraform<span class="w">
</span><span class="w"></span>company.io/fingerprint<span class="p">:</span><span class="w"> </span>abc123<span class="w">
</span><span class="w"></span>company.io/fingerprint-type<span class="p">:</span><span class="w"> </span>sha1<span class="w">
</span><span class="w"></span>company.io/component<span class="p">:</span><span class="w"> </span>database<span class="w">
</span><span class="w"></span>company.io/part-of<span class="p">:</span><span class="w"> </span>wordpress<span class="w">
</span><span class="w"></span>custom.company.io/something-not-standard<span class="p">:</span><span class="w"> </span>this-is-project-or-team-specific</code></pre></div>
<p>Some of these are duplicates of <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/">recommended annotations/labels for kubernetes</a>. <a href="https://dev.to/jeroendedauw/the-fallacy-of-dry">Don&rsquo;t worry about duplication</a>. Use them both, because you&rsquo;ll apply the ones above to more things than just K8s resources. Tools that may not be written by your team could potential benefit from the k8s standard.</p>

<hr />

<p>This will certainly be a multi-part series. Stay tuned for more!</p>
]]></content>
		</item>
		
	</channel>
</rss>
